<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Sukhad Anand: Personal Website</title>


    <!-- Bootstrap Core CSS - Uses Bootswatch Flatly Theme: http://bootswatch.com/flatly/ -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/freelancer.css" rel="stylesheet">
    <link href="css/timeline.css" rel="stylesheet">
   
    <!-- Custom Fonts -->
    <link href="http://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href="http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">

    <script src="js/modernizr.js"></script>
    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top" class="index">

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-about-me-hidden navbar-brand" href="#page-top">Sukhad Anand</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li class="page-scroll">
                        <a href="#timeline">Timeline</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#about">Publications</a>
                    </li>
                    <li class="page-scroll">
                        <a href="#projects">Projects</a>
                    </li>
                    <li>
                        <a href="https://drive.google.com/file/d/0B4fFCuNk7nNtdzdMbzlGRWkwdlU/view?usp=sharing">CV</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->

        </div>
        <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
        <div class="container">
            <div class="row">

                <div class="col-xs-3">
                    <img class="img-responsive img-circle" src="img/a.png" alt="">
                </div>
                <div class="col-xs-9">
                    <div class="intro-text">
                        <span class="name">Sukhad Anand</span>
                        <br>

                        <span class="about_me">
                            I am a senior year BTech Student at Delhi Technological University. My research lies in the field of computer vision and machine learning. I have been involved in building vision applications for various startups around the globe.

                            I find joy in contributing to the vision open source community. I provided a functionality unavialbale in OpenCV, the biggest open source library for computer vision.
                        </span>
                        <hr>
                        <span class="skills"> <ul class="list-inline">
                            <li>
                                <a href="https://scholar.google.co.in/citations?hl=en&user=lRkg9b4AAAAJ"><i class="ai ai-google-scholar"></i></a>
                            </li>
                            <li>
                                <a href="https://www.linkedin.com/in/sukhad-anand-7a1065103/" class="btn-social btn-outline"><i class="fa fa-fw fa-linkedin"></i></a>
                            </li>
                            <li>
                                <a href="https://github.com/sukhad-app"><i class="fa fa-fw fa-github"></i></a>
                            </li>
                        </ul></span>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <section id="timeline">
        <div class="container" >
            <div class="row">
                <section id="cd-timeline" class="cd-container">
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/Briefcase-15.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Remote Research Intern</h2>
                            <span>Aug, 2018</span>
                            <p> IBM </p>
                            <p> Worked on scene transfer applications using Generative Adversarial networks. The work was submitted as poster at AAAI 2019</p>

                        </div> <!-- cd-timeline-content -->
                    </div> <!-- cd-timeline-block -->

                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/Briefcase-15.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Research Engineer</h2>
                            <span>July, 2018</span>
                            <p> Beneufit </p>
                            <p> Developed on a system to predict the level of parkinson's disease using monocular camera and a filed a patent on the same.</p>

                        </div> <!-- cd-timeline-content -->
                    </div> <!-- cd-timeline-block -->

                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/Briefcase-15.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Software Developer Intern</h2>
                            <span>May, 2018</span>
                            <p> Amazon </p>
                            <p> Worked on building APIs in java for the financial technology team</p>
                        </div> <!-- cd-timeline-content -->
                    </div> <!-- cd-timeline-block -->
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/code.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Google Summer of Code (GSOC)</h2>
                            <span>May-June 2017</span>
                            <p> Implemented a research paper to provide the face alignment functionality in OpenCV organisation.</p>

                        </div>
                    </div>
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/light-bulb-3.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Visiting Student Researcher</h2>
                            <span>October, 2016</span>
                            <p> CVML Lab, IIIT-Delhi </p>
                            <p> Worked on various problems in the field of computer vision and machine learning under Dr. Chetan Arora.
                            </p>
                        </div>
                    </div>
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/camera_2.svg" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>Computer Vision developer</h2>
                            <span>October, 2015</span>
                            <p> Autonomous Underwater Vehicle - Delhi Technological University </p>
                            <p> Performed autonomous extraction and segmentation of objects from underwater imagery in natural scene.
                                Developed a robust system for the bot to follow line in the underwater environment.</p>

                        </div>
                    </div>
                    <div class="cd-timeline-block">
                        <div class="cd-timeline-img cd-picture">
                            <img src="img/timeline/graduation_cap_512.png" alt="Picture">
                        </div> <!-- cd-timeline-img -->

                        <div class="cd-timeline-content">
                            <h2>B.Tech in Information Technology</h2>
                            <span>Aug, 2015</span>
                            <p> Started B.Tech from Delhi Technological University </p>
                        </div>
                    </div>
                </section> <!-- cd-timeline -->
            </div>

        </div>
    </section>


    <!-- About Section -->
    <section class="success" id="about">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Publications and Patents</h2>
                    <hr class="star-light">
                </div>
            </div>
            <hr>
            <div class="row">
                <div class="col-sm-3 hidden-xs">
                    <img class="img-responsive" src="img/beneufit.jpg" style="width: 180px;" alt="">
                </div>
                <div class="col-sm-8">
                    <h4 class="pubt">Patent on parkinson's disease prediction using computer vision</h4>
                    <p class="pubd">
                    	Beneufit's mission is to empower people to improve their medical condition through exercise, while supporting vital public health research in an open and ongoing fashion. Our approach is unique in that we prescribe disease-specific exercise interventions and track outcomes through a series of objective measures.
                    	We developed a system using computer vision and machine learning technologies which could predict level of dyskenisia and hence help to diagnose parkinson's disease in a person. The technology is capable enough to make measurements only using a mobile phone camera and hence making it a completely automatic process to measure parkinson's disease.
                	</p>
                    <div class="pubv"></div>
                    <div class="publ">
                     <li><a href="https://www.beneufit.com/">Beneufit</a></li>
                	</div>
                </div>
            </div>
            
            <div class="row">
                <div class="col-sm-3 hidden-xs">
                    <img class="img-responsive" src="img/staq.png" style="width: 180px;" alt="">
                </div>
                <div class="col-sm-8">
                    <h4 class="pubt">Diversity in Fashion Recommendation Using Semantic Parsing</h4>
                    <p class="pubd">
                    	Developing recommendation system for fashion images is
challenging due to the inherent ambiguity associated with
what criterion a user is looking at. Suggesting multiple
images where each output image is similar to the query image
on the basis of a different feature or part is one way
to mitigate the problem. Existing works for fashion recommendation
have used Siamese or Triplet network to learn
features between a similar pair and a similar-dissimilar triplet
respectively. However, these methods do not provide basic
information such as, how two clothing images are similar,
or which parts present in the two images make them similar.
In this paper, we propose to recommend images by
explicitly learning and exploiting part based similarity. We
propose a novel approach of learning discriminative features
from weakly-supervised data by using visual attention over
the parts and a texture encoding network. We show that the
learned features surpass the state-of-the-art in retrieval task
on DeepFashion dataset. We then use the proposed model to
recommend fashion images having an explicit variation with
respect to similarity of any of the parts
                    </p>
                    <h4 class="puba">Sagar verma, Sukhad Anand, Chetan Arora, Atul Rai</h4>
                    <div class="pubv">ICIP 2018</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://ieeexplore.ieee.org/document/8451164">PDF</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-3 hidden-xs">
                    <img class="img-responsive" src="img/crack.png" style="width: 180px;" alt="">
                </div>
                <div class="col-sm-8">
                    <h4 class="pubt">Crack-pot: Autonomous Road Crack and Pothole Detection</h4>
                    <p class="pubd">With the advent of self-driving cars and autonomous robots, it is imperative to detect road impairments like cracks and potholes and to perform necessary evading maneuvers to ensure fluid journey for on-board passengers or equipment. We propose a fully autonomous robust real-time road crack and pothole detection algorithm which can be deployed on any GPU based conventional processing boards with an associated camera. The approach is based on a deep neural net architecture which detects cracks and potholes using texture and spatial features. We also propose pre-processing methods which ensure real-time performance. The novelty of the approach lies in using texture- based features to differentiate between crack surfaces and sound roads. The approach performs well in large viewpoint changes, background noise, shadows, and occlusion. The efficacy of the system is shown on standard road crack datasets.
                    </p>
                    <h4 class="puba">Sukhad Anand, Saksham Gupta,Vaibhav Darbari, Shivam Kohli</h4>
                    <div class="pubv">Digital Image Computing: Techniques and Applications 2018</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://arxiv.org/abs/1810.05107">PDF</a></li>
                        </ul>
                    </div>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-3 hidden-xs">
                    <img class="img-responsive" src="img/fingerprint.png" style="width: 180px;">
                </div>
                <div class="col-sm-8">
                    <h4 class="pubt">Fingerprint Extraction Using Smartphone Camera</h4>
                    <p class="pubd">In the previous decade, there has been a considerable rise in the usage of smartphones.Due to exorbitant advancement in technology, computational speed and quality of image capturing has increased considerably. With an increase in the need for remote fingerprint verification, smartphones can be used as a powerful alternative for fingerprint authentication instead of conventional optical sensors. In this research, wepropose a technique to capture finger-images from the smartphones and pre-process them in such a way that it can be easily matched with the optical sensor images.Effective finger-image capturing, image enhancement, fingerprint pattern extraction, core point detection and image alignment techniques have been discussed. The proposed approach has been validated on FVC 2004 DB1 & DB2 dataset and the results show the efficacy of the methodology proposed. The method can be deployed for real-time commercial usage.
                    </p>
                    <h4 class="puba">Saksham Gupta, Sukhad Anand, Atul Rai</h4>
                    <div class="pubv">Arxiv preprint</div>
                    <div class="publ">
                        <ul>
                            <li><a href="https://arxiv.org/abs/1708.00884">PDF</a></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </section>


            
    <!-- Portfolio Grid Section -->
    <section id="projects">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2>Projects</h2>
                    <hr class="star-light">
                </div>
            </div>

            <!--First Row-->
            <div class="row">
              <div class="col-sm-6">
                <div class="row">
                    <div class="col-xs-6 col-sm-offset-0 col-sm-6 portfolio-item text-center">
                        <a href="#DHL" class="portfolio-link" data-toggle="modal">
                        <img src="img/dhl.png" class="img-responsive" alt="">
                        </a>
                    </div>
                    <div class="col-xs-6 col-sm-offset-0 col-sm-6 portfolio-item text-center">
                        <a href="#Visually" class="portfolio-link" data-toggle="modal">
                        <img src="img/visually.jpeg" class="img-responsive" alt="">
                        </a>
                    </div>
                </div>
                <div class="row">
                    <div class="col-xs-6 col-sm-6 col-sm-offset-0 portfolio-item text-center">
                        <a href="#AUV" class="portfolio-link" data-toggle="modal">
                            <img src="img/auv.jpeg" class="img-responsive" alt="">
                        </a>
                    </div>
                    <div class="col-xs-6 col-sm-6 col-sm-offset-0 portfolio-item text-center">
                        <a href="#Finbot" class="portfolio-link" data-toggle="modal">
                            <img src="img/finbot.png" class="img-responsive" alt="">
                        </a>
                    </div>
                </div>
              </div>

              <div class="col-sm-6">
                <div class="col-xs-12 col-sm-offset-0 col-sm-12 portfolio-item text-center" style="padding-right: 0px; padding-left: 0px">
                    <a href="#OpenCV" class="portfolio-link" data-toggle="modal">
                            <img src="img/opencv.png" class="img-responsive" alt="">
                    </a>
                </div>
              </div>
            </div>
        </div>
    </section>
    

    <!-- Footer -->
    <footer class="text-center">
        <div class="footer-below">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        Copyright &copy; Sukhad Anand 2018
                    </div>
                </div>
            </div>
        </div>
    </footer>

    <!-- Scroll to Top Button (Only visible on small and extra-small screen sizes) -->
    <div class="scroll-top page-scroll visible-xs visible-sm">
        <a class="btn btn-primary" href="#page-top">
            <i class="fa fa-chevron-up"></i>
        </a>
    </div>

    <!-- Portfolio Modals -->
    <div class="portfolio-modal modal fade" id="DHL" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-xs-12">
                        <div class="modal-body">
                            <h2>DHL Chatbot</h2>
                            <br>
                            <img src="img/ss.png" class="img-responsive img-centered" alt="">
                         
                            <p> The bot  is an intelligence that you can count for your parcel related queries , rescheduling orders and notifying when someone is trying to send you something. In this 
                            we use natural language processing to provide human like experience.  </p>

                            <img src="img/ss1.png" class="img-responsive img-centered" alt="">
                            <p> We provide an automatic dimension detection system. With this feature,
                            the user just has to capture the photo of the box to get the size of the box that would be required for packing. </p>

                            <p> We have participated in United by HCL hackathon, 2017, held in Manchester.

                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="http://cloudcv.org">Website</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://github.com/Cloud-CV">Github</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://summerofcode.withgoogle.com/organizations/5746858777378816/">GSOC</a>
                                    </strong>
                                </li>
                            </ul>
                            
                            <div class="row">
                                <div class="col-xs-6">
                                    <h3> Python APIs in action</h3>
                                    <img class="img-responsive" src="https://raw.githubusercontent.com/Cloud-CV/py-cloudcv/b3bb1a362fbd2f3a250419a078d3987db90ff0d7/python_screenshot.gif">
                                </div>
                                <div class="col-xs-6">
                                    <h3> Matlab APIs in action</h3>
                                    <img class="img-responsive" src="https://raw.githubusercontent.com/Cloud-CV/mat-cloudcv/master/matlab_screenshot.gif">

                                </div>
                            </div>

                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Aarush" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>Aarush X-1</h2>
                            <br>
                            <img src="img/Arush_X1.JPG" class="img-responsive img-centered" alt="">
                            <p>Aarush is a prototype of the UAV developed with financial resources and engineering mentoring support
                                from Lockheed Martin Corporation. Traffic Management, Geomatics, Mining Surveillance, Border patrol
                                are just some of the areas in which this UAV can be put to effective, efficient use. </p>
                            <br>
                            <h3> Teaser Video </h3>
                            <br>
                            <iframe src="https://www.youtube.com/embed/BL-Rbf3iEKI" frameborder="0" allowfullscreen style="position: relative; height: 750px; width: 100%;"></iframe>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Origami" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>Origami</h2>
                            <br>
                            <img src="img/origami_banner.png" class="img-responsive img-centered" alt="">
                            <p>Origami (previously called CloudCV-fy your code) is a AI-as-a-service solution that allows researchers to easily convert their deep learning models into an online service that is widely accessible to everyone without the need to setup the infrastructure, resolve the dependencies, and build a web service around the deep learning model. By lowering the barrier to entry to latest AI algorithms, we provide developers, researchers and students the ability to access any model using a simple REST API call.</p>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="http://origami.cloudcv.org">Website</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://github.com/Cloud-CV/Origami">Github</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://gitter.im/Cloud-CV/Origami">Gitter Channel</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="EvalAI" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>EvalAI</h2>
                            <br>
                            <img src="img/evalai_logo.png" class="img-responsive img-centered" alt="">
                            <h3> The Problem: Benchmarking progress in AI is hard </h3>

                            <p>
                                Artificial Intelligence (AI) as a field has progressed significantly in the recent years. A major portion of this progress can be attributed to the proposal of bold new multi-modal AI tasks (recognition, captioning, VQA, Visual Dialog) together with curation of associated datasets -- Common Objects in COntext (COCO), ImageNet, Visual Question Answering (VQA), Stanford Question Answering Dataset (SQUAD), etc. Moving forward, with more datasets being released and new tasks being proposed, comparing a new algorithm with existing algorithms is nontrivial and is hindered by multiple factors:
                            
                                <ol class="list item-details">
                                    <li>Different evaluation schemes for the same task.</li>
                                    <li>Implementation of the different metric or evaluation across different splits of the dataset.</li>
                                    <li>Computational bottlenecks on evaluation servers holding unseen test data.</li>
                                </ol>
                            </p>
                            
                            <h3>The Solution: EvalAI</h3>
                            <p>
                                EvalAI is an open source web platform that aims to help researchers, students and data scientists create, collaborate, and participate in AI challenges. By simplifying and standardizing the process of benchmarking AI, we want to circumvent many of the factors impeding the rate of progress in AI. Our plan is to do this in the following ways: 
                            
                                <ol class="list item-details">
                                    <li>Reduced barrier to entry for hosting AI challenges.</li>
                                    <li>Standardized evaluation protocols (same dataset splits and metrics) for measuring the performance of different algorithms on a given task.<br></li>
                                    <li>Central public leaderboards (“who is the best on X?”).</li>
                                    <li>Faster evaluation of submissions using parallelization techniques that take advantage of distributed multi-core machines.</li>
                                </ol>
                            </p>

                            <h3> Important links: </h3>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="https://evalai.cloudcv.org">Website</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://github.com/Cloud-CV/EvalAI">Github</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://evalai.readthedocs.io/en/latest/">Documentation</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://gitter.im/Cloud-CV/EvalAI">Gitter Link</a>
                                    </strong>
                                </li>
                            </ul>
                    
                            <h3> How it is different from Kaggle? </h3>
                            <p>
                                The central differences are:
                            
                            <ul class="list item-details">
                                <li> Custom Evaluation Protocols and Phases: We have designed versatile backend framework that can support user-defined evaluation metrics, various evaluation phases, private and public leaderboard. </li>
                                <li> Faster Evaluation: The backend evaluation pipeline is engineered so that submissions can be evaluated parallelly using multiple cores on multiple machines via mapreduce frameworks offering a significant performance boost over similar web AI-challenge platforms.</li>
                                <li>Portability: Since the platform is open-source, users have the freedom to host challenges on their own private servers rather than having to explicitly depend on Cloud Services such as AWS, Azure, etc.</li>
                                <li>Centralized Leaderboard: Challenge Organizers whether host their challenge on EvalAI or forked version of EvalAI, they can send the results to main EvalAI server. This helps to build a centralized platform to keep track of different challenges.</li>
                                
                            </ul>
                            </p>
                            

                            <h3> Performance comparisons with other platforms: </h3>

                            <p> EvalAI hosted Visual Question Answering (VQA) 2017 challenge as its first challenge. To give some background, last year, the VQA 2016 challenge was hosted on Codalab, and on average evaluation would take ~10 minutes. This year, the dataset for the VQA Challenge 2017 was twice as large. Despite this, we have found that our parallelized backend took only ~130 seconds to evaluate on the whole test set of VQA dataset. </p>

                            <h3> Research Organizations using EvalAI: </h3>
                            
                            <div class="row">
                            <div class="col-xs-3"><img src="https://evalai.cloudcv.org/dist/images/organizations/fb.png" class="img-responsive img-centered" alt=""></div>
                            <div class="col-xs-3"><img src="https://evalai.cloudcv.org/dist/images/organizations/google.png" class="img-responsive img-centered" alt=""></div>
                            <div class="col-xs-3"><img src="https://evalai.cloudcv.org/dist/images/organizations/mapillary.png" class="img-responsive img-centered" alt=""></div>
                            <div class="col-xs-3"><img src="https://evalai.cloudcv.org/dist/images/organizations/gt.png" class="img-responsive img-centered" alt=""></div>
                            </div>
                            
                            <br>
                            <br>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Fabrik" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>Fabrik</h2>
                            <br>
                            <img src="https://github.com/Cloud-CV/Fabrik/raw/master/example/fabrik_demo.gif?raw=true" class="img-responsive img-centered" alt="">
                            <p> Fabrik is an online collaborative platform to build, visualize and train deep learning models via a simple drag-and-drop interface. It allows researchers to collaboratively develop and debug models using a web GUI that supports importing, editing and exporting networks written in widely popular frameworks like Caffe, Keras, and TensorFlow.</p>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="http://fabrik.cloudcv.org">Website</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://github.com/Cloud-CV/Fabrik">Github</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="https://gitter.im/Cloud-CV/IDE">Gitter Channel</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Garuda" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>Garuda</h2>
                            <br>
                            <img src="img/garuda.jpg" class="img-responsive img-centered" alt="">
                            <p>GARUDA, a modified Sig Rascal 110 R/C aircraft along with its Ground Control System is capable of performing
                                autonomous flight & navigation, simultaneously gathering actionable surveillance data using optical sensors.
                                The system includes commercially available autopilot system, Piccolo II for control & navigation with a customized
                                imagery system capable of capturing & transmitting high definition images of the hostile territory simultaneously
                                processing it to deliver actionable intelligence. The Ground Control Station (GCS) and the aircraft communicate
                                in real time to provide situational awareness and safe and reliable flight. Due to it's modular design, the entire system
                                can be brought to a flying state in less than 20 minutes. We participated with this system in Student Unmanned Aerial Systems (SUAS) 2012 competition and secured 3rd position.</p>
                            
                            <p> Garuda was developed as part of the Unmanned Aerial Systems - Delhi Technological University (UAS-DTU) project. UAS-DTU is a team of undergraduate students of Delhi Technological University, devoted to developing indigenous technological solutions for UAVs. Our ultimate goal was to reduce India's reliance on off-the-shelf products and foreign UAVs. Focussing on humanitarian uses of UAVs, we are developing a new generation of low-cost Image Processing and Flight Control Systems to aid in Surveillance and Reconnaissance.</p>

                            <p>The team, under mentorship and funding from Lockheed Martin, is the first to develop a Next Generation Urban UAS - Aarush X1, that is tailor- made for surveillance in urban jungles like Delhi and Mumbai. The team signed its first MoU with Lockheed Martin in 2009. The second MoU was signed in 2013, under which a new version of Aarush (Aarush X2) is being developed. The team annually participates in AUVSIs SUAS competition, which stands for Student Unmanned Aerial Systems competition. The competition is held in Maryland, USA where more than 30 universities come every year with their UAVs hoping to win the competition. We are the first team from India to participate in this competition (Our first participation was in 2009), and also the first team from India to achieve a podium finish (We were ranked 3rd in 2012). In 2013, the team ranked 6th. After these years of experience through the competition and Lockheed Martin project, we are now capable of manufacturing Unmanned Aerial Systems for the market with the capabilities of Aerial Imagery, and GCS Softwares for the processing of these images.</p>
                            <br>
                            <h3>Video: Journey of UAS-DTU</h3>
                            <br>
                            <iframe src="https://www.facebook.com/video/embed?video_id=10151167933007739" width="560" height="315" style="border:none;overflow:hidden" scrolling="no" frameborder="0" allowTransparency="true" allowFullScreen="true"></iframe>
                            <br>
                            <h3>Important Links</h3>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="img/journal_2012.pdf">Journal Paper</a>
                                    </strong>
                                </li>
                                <li>
                                    <strong><a href="http://www.thehindu.com/todays-paper/tp-features/tp-educationplus/laurels-for-team-uasdtu/article3796999.ece">Article in The Hindu</a>
                                    </strong>
                                </li>
                            </ul>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="AMTChat" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>AMT Chat Interface</h2>
                            <br>
                            <img src="img/amtchat.png" class="img-responsive img-centered" alt="">
                            <p>Source for the two-person chat interface used to collect the VisDial dataset on Amazon Mechanical Turk. A demo is available <href src="https://godel.ece.vt.edu/visdial_chat/">here</href> (open in two separate tabs to be paired for conversation).</p>
                            <ul class="list-inline item-details">
                                <li>
                                    <strong><a href="https://github.com/batra-mlp-lab/visdial-amt-chat">Github</a>
                                    </strong>
                                </li>

                            </ul>
                            <h3> How things works </h3>
                            <p>
                                The real-time chat interface is built using Node.js and Socket.io. We use Redis to maintain a pool of images for live HITs and all data finally resides in a MySQL database.
                                <br><br>
                                A database table stores images from the COCO dataset each with a randomly picked caption. A batch of images from this table are then pushed to a Redis list for launching HITs. The web server corresponding to the chat interface pairs two AMT workers, assigns them roles (questioner or answerer) and shows corresponding interface, picks an image from the Redis list to collect data on and saves their conversation in the database, also marking that image as 'complete' once the HIT is done. This happens in parallel so workers aren't left waiting, and the server ensures workers have unique ids. Disconnects are handled gracefully — remaining worker is asked to continue asking questions or providing facts (captions) up to 10 messages. Once the HITs are complete, scripts in mturk_scripts/approve can be used to review, approve, reject HITs and pay workers.

                            </p>
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="NoteWorthy" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>NoteWorthy</h2>
                            <br>
                            <div class="row">
                                <div class="col-xs-3 col-md-3">
                                    <img src="img/noteworthy1.png" class="img-responsive img-centered" alt=""></div>
                                <div class="col-xs-3 col-md-3">
                                    <img src="img/noteworthy2.png" class="img-responsive img-centered" alt="" ></div>
                                <div class="col-xs-3 col-md-3">
                                    <img src="img/noteworthy3.png" class="img-responsive img-centered" alt=""></div>
                                <div class="col-xs-3 col-md-3">
                                    <img src="img/noteworthy4.png" class="img-responsive img-centered" alt=""></div>
                            </div>
                            <div class="row">
                            <p>What if you could replace the slow and monotone professor with complete and efficient notes? Rather than begging for them from the smartest students in class, Noteworthy provides a smart alternative ecosystem of notes. Whether you've simply wanted to skip a class without the academic problems, or you wanted to reinforce your education, Noteworthy gives you the greatest studying experience. Noteworthy, an app founded at MHacks, allows for easy and seamless digitization of notes. Noteworthy takes the noteworthiest notes from across the world, and brings them to you anywhere. With course, professor, and date choices, students can find the right notes for the right class on the right day. Noteworthy will save you time and get you better results for your education.</p>

                            <p>Noteworthy was developed while participating in MHacks 2014 - one of the biggest 48 hour hackathon competition orgamized by University of Michigan, Ann Arbor</p>
                            </div>

                            
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Trippr" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <div class="modal-body">
                            <h2>Trippr</h2>
                            <br>
                            
                            <p> Trippr is a collaborative trip planning app powered by IBM Watson based personal assistant. This app was developed while participating 
                            in Angel Hacks, Seattle - a 24 hour hackathon in the summer of 2013. It consisted of a combination of Android app, Pebble Smartwatch app and a Web app through which
                            people can chat online with their friends, ask questions to a smart personal assistant and book iteneraries. </p>

                            <p> The personal assistant powered by IBM Watson can hold conversation with the group of users to suggest popular destinations, restaurants, cheapest flights. It also automatically built an itenerary based on users choices. This app provided smart features similar to Google Trips.</p>

                            <p> Our app also won the "Best use of Respoke API" award.</p>
                            
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="portfolio-modal modal fade" id="Mobishare" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-content">
            <div class="close-modal" data-dismiss="modal">
                <div class="lr">
                    <div class="rl">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12">
                        <div class="modal-body">
                            <h2>Mobishare</h2>
                            <br>
                            <img src="img/MSR_TechV2013.jpg" class="img-responsive img-centered" alt="">
                            <p>
                                
                            </p>
                            
                            <button type="button" class="btn btn-default" data-dismiss="modal"><i class="fa fa-times"></i> Close</button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="js/classie.js"></script>
    <script src="js/cbpAnimatedHeader.js"></script>

    <script src="js/timeline.js"></script>
    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/freelancer.js"></script>
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-92670333-1', 'auto');
        ga('send', 'pageview');

    </script>
</body>

</html>
